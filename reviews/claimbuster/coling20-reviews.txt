============================================================================
                            REVIEWER #1
============================================================================

---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                         Relevance (1-5): 5
               Readability/clarity (1-5): 5
                       Originality (1-5): 3
   Technical correctness/soundness (1-5): 4
                   Reproducibility (1-5): 5
                         Substance (1-5): 3

Detailed Comments
---------------------------------------------------------------------------
The paper study the well-known problem of adversarial training in natural language understanding.
The authors choose to study one specific sequence classification task which is fact-checkworthy-ness.
As expected, the perturbation approach is improving SoA in 2 small-sized dataset, why not using fever dataset instead ?
While the analysis is well explained and rigorous, it missed novelty and originality.
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
            Overall recommendation (1-5): 2
                        Confidence (1-5): 4
                       Presentation Type: Poster
     Recommendation for Best Paper Award: No


============================================================================
                            REVIEWER #2
============================================================================

---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                         Relevance (1-5): 5
               Readability/clarity (1-5): 5
                       Originality (1-5): 3
   Technical correctness/soundness (1-5): 4
                   Reproducibility (1-5): 4
                         Substance (1-5): 2

Detailed Comments
---------------------------------------------------------------------------
This paper proposes to use adversarial perturbation (on the input embeddings) to train a check-worthy classifier (i.e. whether the sentence contains a fact that could be checked or not). 

Besides the (limited) improved performance of the model, the most interesting part of the paper (at least for me) was the study and experiments on what part of the embeddings should be perturbed when using a BERT-like model: the token embedding, the positional embedding or the part embedding.


The first weakness of the paper is that it does not include a review of adversarial regularization when training the models.

The second weaknesses of the paper is the quality of its writing and the interest of its content in some parts: 
- section 2.1.2 is unnecessary now (BERT is now a well known model)
- table 2: what are the different lines?
- p.7: please describe the different metrics and those that are the most important. Also, why didn't you use MAP in the first experiments since the class of check-worthy claims is much smaller than the other (as done in the CLEF evaluation)?
- table 3: what is P_m and P_w ?
- In section 3.4.3, the authors show two distributions (for SVM and BBA), showing that with the proposed approach (BBA) the distribution was bimodal - why would this be interesting? On the contrary, this could mean that the model is confident when it makes a mistake (which is not a positive point).
 
The third is the lack of experiments showing that adversarial training does improve things compared for example with random perturbations - this is important since there is some overhead with adversarial training. Also, since the perturbations can be applied to any differentiable model, why didn't the author try with other architectures to see how the approach performs (at least with one different architecture).
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
            Overall recommendation (1-5): 2
                        Confidence (1-5): 3
                       Presentation Type: Poster
     Recommendation for Best Paper Award: No


============================================================================
                            REVIEWER #3
============================================================================

---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                         Relevance (1-5): 5
               Readability/clarity (1-5): 5
                       Originality (1-5): 4
   Technical correctness/soundness (1-5): 4
                   Reproducibility (1-5): 4
                         Substance (1-5): 4

Detailed Comments
---------------------------------------------------------------------------
This paper proposes a method for the task of check-worthy factual claims detection, which is treated as a text classification problem. Bert is used as the classifier. Moreover, to increase the robustness of the training Bert, the authors apply adversarial training where perturbations on the embeddings of BERT are computed and incorporated into Bert training. The results show that adversarial training of Bert on this specific task leads to better performance than not using adversarial training.

Pros:
The paper is very well-written and easy to follow. The methodology is clearly explained and techicailly sound. The experiments show a large improvement in F1 achieved by the proposed method.

Cons:
1) The proposed method seems to be general enough to apply to other tasks as well, in addition to the one studied in the paper, so it would be more interesting if some task-specific knowledge can be exploited by the Bert-based method to gain further improvement.
2) Constraining the magnitude of the permutation with a small boundary seems a standard way of getting reasonable permutations, which might affect the originality a bit, but the explanation of this emthod in section 2.4.2 is very clear.
---------------------------------------------------------------------------