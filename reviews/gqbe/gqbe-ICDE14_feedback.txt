We'd like to thank all reviewers for the insightful comments that will help us in preparing the camera-ready version. 

Review 1:

Q1.1: “How would a user come up with the examples and what structure those examples would take?”

A1.1: A user doesn't need to specify any structure for example tuples. As long as she knows one or more example tuples that satisfy her intent, she only has to list the entities in each example tuple. E.g., a software engineer knows a few founder-company pairs and may want to find similar pairs. The system aims at figuring out how the entities are related. 

Q1.2: “How does the size of the neighborhood graph affect precision and recall...”

A1.2: The parameter 'd' influences the size of neighborhood graph (NG). A larger NG has a higher chance of capturing more important relationships in the resulting MQG. If the MQG misses important relationships, it affects query result accruacy. In the camera-ready version, we will include an experiment of the effect of 'd' (hence the size of NG) on  accuracy.

Review 2:

Q2.1: “it assumes that the user understands how the algorithm works”, “it does not seem very easy how to come up with good query tuples ..." 

A2.1: The user need not to know the working of the algorithm. She only provides one or more example tuples.

Our premise is that it is more realistic for a user to know some example tuples than writing structured queries. For instance, a software engineer knows a few founder-company pairs and may want to find similar pairs. Note that works on "set expansion" are also based on this premise, espeically Google Squared and [11], which take tuples of entities as input. 

Admittedly, every query approach puts some burden on users. While GQBE requires knowing the names of some example entities, the user needs not to know how exactly the entities are related. In contrary, the paradigm of keyword search doesn't require the names of answers, but the user has to articulate query conditions by keywords. 

Q2.2: “... difficult for the user to understand why the particular results come up (instead of others), ... there is no specific way to guide the system to get better results.”

A2.2: These are very good points related to important future directions of the work. Both answering Why-Not questions and improving queries by user guidance such as feedback can be helpful. However, we believe these are not in the scope of this paper.

That being said, GQBE currently allows a user to view the maximal query graph and the answer graphs associated with answer tuples, as an initial step in helping users understand query answers. This feature can be found in a short video at http://www.youtube.com/watch?v=4QfcV-OrGmQ. 

Q2.3: “The authors do not provide arguments to support why the proposed approach is more suitable than these methods" (keyword search, interactive query formulation, ...), "... no comparison with any such method in the experimental evaluation”

A2.3: These approaches, including GQBE, all have their suitable and unsuitable use scenarios. (E.g., comparison of keyword search and GQBE in A2.1.) Hence, they do not replace each other. Instead, they are complementary. They may all provide better usability than writing structured queries. 

An experimental comparison of these querying paradigms are difficult to find in the context of querying a large knowledge graph. One particular challenge in making such a comparison is that they take different forms and content of input (cf. the comparison of keyword search and GQBE in A2.1). It is an important future direction and we are very interested in conducting such a study.  

Q2.4: “... no discussion how these parameters and weights are determined and how much they affect the results. "

A2.4: In the camera-ready version, we will include results on how the parameters and weighting methods affect query accuracy/efficiency. We may have to include detailed results in an extended report. 

Review 3:

Q3.1: (D2) in the review.

A3.1:  We have difficulty in understanding what are meant by "loose notion of neighborhood" and "structural properties". It is highly appreciated if it is clarified. We will improve the camera-ready version accordingly to make it more clear. Note that the aim of MQG discovery is to retain the most important edges from the neighborhood graph (NG).

Q3.2: (D3) in the review.

A3.2: In a well-connected data graph, the NG can have over 100,000 edges. It is important to reduce the size for evaluating the query lattice efficiently, hence the step of reducing NG to MQG. We will make this point more clear. 

Q3.3: (D5) in the review.

A3.3: The system does take entities and relationships into account. Relationships between entities are critical in creating and evaluating the MQG.
